{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Thực thi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Hàm đếm từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens_simple(text):\n",
    "    # Tách từ bằng cách sử dụng khoảng trắng\n",
    "    tokens = text.split()\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hàm xử lý tên file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_name(file_name):\n",
    "    parts = file_name.replace('.docx', '').split('_')\n",
    "    \n",
    "    if len(parts) != 7:\n",
    "        return None  # Nếu file không hợp lệ\n",
    "    \n",
    "    loai_van_ban = parts[0]\n",
    "    noi_ban_hanh = parts[1]\n",
    "    so_hieu = parts[2].replace(\"-\", \"/\")\n",
    "    linhvuc_nganh = parts[3]\n",
    "    ngay_ban_hanh = parts[4].replace(\"-\", \"/\")\n",
    "    ngay_hieu_luc = parts[5] if parts[5] == \"Đã biết\" else parts[5].replace(\"-\", \"/\")\n",
    "    chu_de = parts[6]\n",
    "    \n",
    "    return {\n",
    "        \"loai_van_ban\": loai_van_ban,\n",
    "        \"noi_ban_hanh\": noi_ban_hanh,\n",
    "        \"so_hieu\": so_hieu,\n",
    "        \"linhvuc_nganh\": linhvuc_nganh,\n",
    "        \"ngay_ban_hanh\": ngay_ban_hanh,\n",
    "        \"ngay_hieu_luc\": ngay_hieu_luc,\n",
    "        \"chu_de\": chu_de\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Hàm trích xuất các từ khóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ dấu câu\n",
    "    words = text.split()\n",
    "    unique_words = list(dict.fromkeys(words))  # Loại bỏ từ trùng lặp\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Hàm đọc và xử lý nội dung của file .docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docx(file_path, max_tokens):\n",
    "    document = Document(file_path)\n",
    "    \n",
    "    current_chapter = None\n",
    "    current_section = None\n",
    "    current_mini_section = None\n",
    "    data = []\n",
    "    \n",
    "    for i in range(len(document.paragraphs)):\n",
    "        paragraph_text = document.paragraphs[i].text.strip()\n",
    "        \n",
    "        if paragraph_text.startswith(\"Chương\"):\n",
    "            current_chapter = paragraph_text\n",
    "            current_section = None\n",
    "            current_mini_section = None\n",
    "            if i + 1 < len(document.paragraphs):\n",
    "                next_paragraph = document.paragraphs[i + 1].text.strip()\n",
    "                if not next_paragraph.startswith((\"Mục\", \"Tiểu mục\", \"Điều\")):\n",
    "                    current_chapter += f\": {next_paragraph}\"\n",
    "            continue\n",
    "        \n",
    "        if paragraph_text.startswith(\"Mục\"):\n",
    "            current_section = paragraph_text\n",
    "            current_mini_section = None\n",
    "            continue\n",
    "        \n",
    "        if paragraph_text.startswith(\"Tiểu mục\"):\n",
    "            current_mini_section = paragraph_text\n",
    "            continue\n",
    "        \n",
    "        if paragraph_text.startswith(\"Điều\"):\n",
    "            article = paragraph_text\n",
    "            content = []\n",
    "            \n",
    "            for j in range(i + 1, len(document.paragraphs)):\n",
    "                next_paragraph = document.paragraphs[j].text.strip()\n",
    "                if next_paragraph.startswith((\"Chương\", \"Mục\", \"Tiểu mục\", \"Điều\")):\n",
    "                    break\n",
    "                content.append(next_paragraph)\n",
    "            \n",
    "            # Chuyển đổi nội dung thành chuỗi với dấu xuống dòng\n",
    "            content_text = \"\\n\".join(content)\n",
    "            combine_article_content = f\"{article}\\n{content_text}\"\n",
    "            key_words = extract_keywords(combine_article_content)\n",
    "\n",
    "            # Kiểm tra số lượng tokens của nội dung\n",
    "            if count_tokens_simple(content_text) > max_tokens - count_tokens_simple(article):\n",
    "                # Tách nội dung thành từng phần dựa trên số thứ tự (1., 2., 3., ...)\n",
    "                numbered_sections = re.split(r'(?=\\d+\\.\\s)', content_text)\n",
    "\n",
    "                current_content = \"\"\n",
    "                for section in numbered_sections:\n",
    "                    # Kiểm tra số lượng tokens sau khi cộng thêm section\n",
    "                    if count_tokens_simple(current_content + section) <= max_tokens - count_tokens_simple(article):\n",
    "                        current_content += section + \"\\n\"  # Thêm xuống dòng\n",
    "                    else:\n",
    "                        # Lưu phần nội dung hiện tại\n",
    "                        data.append({\n",
    "                            \"Chapter\": current_chapter,\n",
    "                            \"Section\": current_section if current_section else None,\n",
    "                            \"Mini-Section\": current_mini_section if current_mini_section else None,\n",
    "                            \"Article\": article,\n",
    "                            \"Content\": current_content.strip(),\n",
    "                            \"combine_Article_Content\": f\"{article}\\n{current_content.strip()}\",\n",
    "                            \"key_words\": key_words\n",
    "                        })\n",
    "                        current_content = section + \"\\n\"  # Thêm xuống dòng\n",
    "\n",
    "                # Lưu phần nội dung còn lại nếu có\n",
    "                if current_content:\n",
    "                    data.append({\n",
    "                        \"Chapter\": current_chapter,\n",
    "                        \"Section\": current_section if current_section else None,\n",
    "                        \"Mini-Section\": current_mini_section if current_mini_section else None,\n",
    "                        \"Article\": article,\n",
    "                        \"Content\": current_content.strip(),\n",
    "                        \"combine_Article_Content\": f\"{article}\\n{current_content.strip()}\",\n",
    "                        \"key_words\": key_words\n",
    "                    })\n",
    "            else:\n",
    "                # Nếu nội dung nhỏ hơn max_tokens - length of article\n",
    "                data.append({\n",
    "                    \"Chapter\": current_chapter,\n",
    "                    \"Section\": current_section if current_section else None,\n",
    "                    \"Mini-Section\": current_mini_section if current_mini_section else None,\n",
    "                    \"Article\": article,\n",
    "                    \"Content\": content_text.strip(),\n",
    "                    \"combine_Article_Content\": f\"{article}\\n{content_text.strip()}\",\n",
    "                    \"key_words\": key_words\n",
    "                })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Hàm chính xử lý tất cả các file trong thư mục"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, output_json_path, max_tokens):\n",
    "    all_data = []\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".docx\"):\n",
    "            file_metadata = process_file_name(file_name)\n",
    "            if file_metadata is None:\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            docx_data = process_docx(file_path, max_tokens=max_tokens)\n",
    "            \n",
    "            for entry in docx_data:\n",
    "                combined_entry = {**file_metadata, **entry}\n",
    "                all_data.append(combined_entry)\n",
    "    \n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Dữ liệu đã được lưu vào file {output_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Thực thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới thư mục và file đầu ra\n",
    "folder_path = r'data\\trich_dan_luat\\docx\\Luat'\n",
    "json_file_path = r'data\\trich_dan_luat\\json\\test_Combined_Output_Token.json'\n",
    "max_tokens = 2048  # Giới hạn số token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lưu vào file data\\trich_dan_luat\\json\\test_Combined_Output_Token.json\n"
     ]
    }
   ],
   "source": [
    "# Chạy chương trình chính\n",
    "process_folder(folder_path, json_file_path, max_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
