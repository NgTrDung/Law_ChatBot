{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_qdrant import Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Thực thi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load folder .docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_data_docx = r\"data\\trich_dan_luat\\docx\\Luat\"\n",
    "os.chdir(folder_data_docx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Load file .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_json = r'D:\\Download_Github_Desktop\\Law_ChatBot\\Vector_Database_Qdrant\\data\\trich_dan_luat\\json\\extract_Data_FileName.json'\n",
    "with open(file_name_json, 'r', encoding='utf-8') as file:\n",
    "    data_json = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Model Embedidng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_MODEL = \"bkai-foundation-models/vietnamese-bi-encoder\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=EMBEDDINGS_MODEL,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Semantic Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    embeddings=embeddings, breakpoint_threshold_type=\"gradient\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "URL_QDRANT = os.getenv(\"URL_QDRANT\")\n",
    "API_QDRANT = os.getenv(\"API_QDRANT\")\n",
    "\n",
    "url = URL_QDRANT\n",
    "api_key = API_QDRANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, f in enumerate(glob.glob('*.docx')):\n",
    "\traw_documents = Docx2txtLoader(f).load()\n",
    "\tdocs = text_splitter.split_documents(raw_documents)\n",
    "\tmetadata = data_json[idx]\n",
    "\tfor doc in docs:\n",
    "\t\tsetattr(doc, \"metadata\", metadata) \n",
    "\tqdrant = Qdrant.from_documents(\n",
    "\t\tdocuments=docs,\n",
    "\t\tembedding=embeddings,\n",
    "\t\turl=url,\n",
    "\t\tapi_key = api_key,\n",
    "\t\tcollection_name=\"semantic_Luat\",\n",
    "\t\tmetadata_payload_key=\"metadata\",\n",
    "\t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
