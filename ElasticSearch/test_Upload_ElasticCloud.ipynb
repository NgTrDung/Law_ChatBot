{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_PDF = r'data\\tinh_huong/output.pdf'\n",
    "raw_documents = PyPDFLoader(file_PDF).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trang 1:\n",
      "Situation:\n",
      "Tôi xin hỏi, học sinh vừa tốt nghiệp THPT khi xét tuyển vào các trường cao đẳng thì có được tạm\n",
      "miễn thực hiện nghĩa vụ quân sự không?\n",
      "Answer:\n",
      "Bộ Quốc phòng trả lời vấn đề này như sau:Theo quy định tại Điểm g Khoản 1 Điều 41Luật Nghĩa vụ\n",
      "quân sựnăm 2015, những công dân sau đây được tạm hoãn gọi nhập ngũ:\"g) Đang học tại cơ sở\n",
      "giáo dục phổ thông; đang được đào tạo trình độ đại học hệ chính quy thuộc cơ sở giáo dục đại học,\n",
      "trình độ cao đẳng hệ chính quy thuộc các cơ sở giáo dục nghề nghiệp trong một khóa đào tạo của\n",
      "một trình độ đào tạo\".Như vậy, công dân thuộc trường hợp nêu tại Điểm g Khoản 1 Điều 41 Luật\n",
      "Nghĩa vụ quân sự năm 2015 được tạm hoãn từ ngày công dân đã làm xong thủ tục nhập học và\n",
      "đang học tập tại trường; chỉ được tạm hoãn gọi nhập ngũ trong một khóa đào tạo tập trung đầu\n",
      "tiên, còn các khóa học tiếp theo thì không được tạm hoãn.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Trang 2:\n",
      "Situation:\n",
      "Hiện  nay  khi  tra  cứu  trên  Hệ  thống  thông  tin  giải  quyết  thủ  tục  hành  chính  Bộ  Y  tế\n",
      "(https://dichvucong.moh.gov.vn)  hoặc  Cổng  Thông  tin  điện  tử  về  quản  lý  trang  thiết  bị  y  tế\n",
      "(https://dmec.moh.gov.vn/) đều không có thông tin về các cá nhân đủ điều kiện tư vấn về kỹ thuật\n",
      "trang thiết bị y tế. Việc này gây khó khăn cho các cơ quan, đơn vị, chủ đầu tư khi lập danh mục và\n",
      "xây dựng cấu hình, tính năng kỹ thuật trang thiết bị y tế.  Tôi đề nghị Bộ Y tế hướng dẫn cụ thể\n",
      "việc tra cứu thông tin về các cá nhân đủ điều kiện tư vấn về kỹ thuật trang thiết bị y tế để các chủ\n",
      "đầu tư có thể lựa chọn làm tư vấn lập danh mục và xây dựng cấu hình, tính năng kỹ thuật trang\n",
      "thiết bị y tế theo quy định.  Ngoài ra, Thông tư số 14/2023/TT-BYT ngày 30/6/2023 của Bộ trưởng\n",
      "Bộ Y tế ban hành quy định trình tự, thủ tục xây dựng giá gói thầu mua sắm hàng hóa và cung cấp\n",
      "dịch vụ thuộc lĩnh vực trang thiết bị y tế tại các cơ sở y tế công lập có hiệu lực từ ngày 1/7/2023\n",
      "đến ngày 31/12/2023, nhưng đến nay Bộ Y tế vẫn chưa ban hành Thông tư mới để thay thế, dẫn\n",
      "đến các chủ đầu tư gặp vướng mắc trong việc lập các gói thầu mua sắm trang thiết bị y tế.\n",
      "Answer:\n",
      "Bộ Y tế trả lời vấn đề này như sau:Thực hiện theo quy định tại Điểm b Khoản 2 Điều 54 Nghị định\n",
      "số98/2021/NĐ-CPcủa Chính phủ về quản lý trang thiết bị y tế; hiện nay, Bộ Y tế (Cục Cơ sở hạ tầng\n",
      "và thiết bị y tế) đã tiếp nhận và công bố danh sách các cá nhân đủ điều kiện tư vấn về kỹ thuật\n",
      "trang  thiết  bị  y  tế  trên  Cổng  Thông  tin  điện  tử  về  quản  lý  trang  thiết  bị  y  tế\n",
      "(https://dmec.moh.gov.vn/).Để  có  thể  tra  cứu  thông  tin,  đề  nghị  thực  hiện  theo  các  bước  sau:-\n",
      "Truy cập vào Cổng Thông tin điện tử về quản lý trang thiết bị y tế (https://dmec.moh.gov.vn/);-\n",
      "Click  vào  module  \"Kết  quả  dịch  vụ  công\";-  Vào  ô  tìm  kiếm  gõ  \"TVKT\"  (Viết  tắt  của  Tư  vấn  kỹ\n",
      "thuật);- Click vào ô \"Tìm kiếm\" và xem xét hồ sơ, thông tin của các cá nhân đủ điều kiện tư vấn đã\n",
      "được  công  bố.Về  việc  ban  hành  Văn  bản  quy  phạm  pháp  luật  thay  thế  Thông  tư  số\n",
      "14/2023/TT-BYT, ngày 23/6/2023, Quốc hội đã ban hành Luật Đấu thầu số 22/2023/QH15; ngày\n",
      "27/2/2024, Chính phủ đã ban hành Nghị định số 24/2024/NĐ-CP quy định chi tiết một điều và biện\n",
      "pháp thi hành Luật Đấu thầu về lựa chọn nhà thầu.Theo đó, các nội dung liên quan đến xây dựng\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Trang 3:\n",
      "giá gói thầu và tổ chức lựa chọn nhà thầu đối với các mặt hàng, dịch vụ liên quan đến hóa chất, vật\n",
      "tư xét nghiệm thiết bị y tế được quy định tại Điều 16 Nghị định số 24/2024/NĐ-CP. Vì vậy, đề nghị\n",
      "cá nhân/ tổ chức quan tâm có thể nghiên cứu để triển khai, thực hiện.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Trang 4:\n",
      "Situation:\n",
      "Tôi tốt nghiệp cao đẳng dược, đã có chứng chỉ hành nghề y và làm việc tại 1 bệnh viện thuộc TP.\n",
      "Hải Phòng. Xin hỏi, tôi muốn làm thêm chứng chỉ hành nghề dược có được không? Có phải bỏ\n",
      "chứng chỉ y để làm chứng chỉ dược không? Có thể sử dụng song song 2 chứng chỉ này được không?\n",
      "Answer:\n",
      "Bộ Y tế trả lời vấn đề này như sau:TạiLuật Dượcvà các văn bản quy phạm pháp luật có liên quan về\n",
      "dược không có quy định về việc một cá nhân không được có đồng thời chứng chỉ hành nghề dược\n",
      "và chứng chỉ hành nghề y.Cá nhân đáp ứng điều kiện về văn bằng chuyên môn, thời gian thực\n",
      "hành chuyên môn và các điều kiện khác theo quy định tại Luật Dược năm 2016 (các Điều từ 13 đến\n",
      "22) và Nghị định số54/2017/NĐ-CPngày 8/5/2017 của Chính phủ quy định chi tiết một số điều và\n",
      "biện  pháp  thi  hành  Luật  Dược  (được  sửa  đổi,  bổ  sung  bởi  Nghị  định  số155/2018/NĐ-CPngày\n",
      "12/11/2018 của Chính phủ sửa đổi, bổ sung một số quy định liên quan đến điều kiện đầu tư kinh\n",
      "doanh thuộc phạm vi quản lý nhà nước của Bộ Y tế) có thể chuẩn bị hồ sơ đề nghị cấp chứng chỉ\n",
      "hành nghề dược và nộp cho cơ quan có thẩm quyền để được xem xét cấp chứng chỉ hành nghề\n",
      "dược theo quy định.Cá nhân khi đảm nhiệm một trong các vị trí công việc quy định tại Điều 11 Luật\n",
      "Dược năm 2016 cần có chứng chỉ hành nghề dược.Luật Dược và các văn bản quy phạm pháp luật\n",
      "có liên quan về dược không có quy định về việc cá nhân không được sử dụng chứng chỉ hành nghề\n",
      "dược đồng thời với các chứng chỉ hành nghề khác (như nghề y). Người hành nghề dược có quyền\n",
      "và nghĩa vụ theo quy định tại Mục 2 Chương III Luật Dược năm 2016 và phải thực hiện các quy\n",
      "định có liên quan theo quy định của pháp luật về dược khi sử dụng chứng chỉ hành nghề dược.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Trang 5:\n",
      "Situation:\n",
      "Tôi là kỹ sư an toàn thực phẩm, làm việc tại Khoa An toàn thực phẩm thuộc Trung tâm Y tế huyện\n",
      "từ năm 2010, mã ngạch 13.095 (chưa chuyển sang mã V.05).   Xin hỏi, tôi có được hưởng phụ cấp\n",
      "ưu đãi nghề theo Nghị định số 56/2011/NĐ-CP và Nghị định số 05/2023/NĐ-CP không?\n",
      "Answer:\n",
      "Bộ Y tế trả lời vấn đề này như sau:Hiện nay, chế độ phụ cấp ưu đãi theo nghề đối với công chức,\n",
      "viên chức công tác tại các cơ sở y tế công lập thực hiện theo quy định tại các văn bản: Nghị định\n",
      "số56/2011/NĐ-CPngày 4/7/2011 của Chính phủ; Nghị định số05/2023/NĐ-CPngày 15/2/2023 của\n",
      "Chính phủ sửa đổi bổ sung một số điều của Nghị định số 56/2011/NĐ-CP quy định chế độ phụ cấp\n",
      "ưu đãi theo nghề đối với công chức, viên chức công tác tại các cơ sở y tế công lập; Thông tư liên\n",
      "tịch số02/2012/TTLT-BYT-BNV-BTCngày 19/1/2012 của Bộ Y tế, Bộ Nội vụ, Bộ Tài chính hướng dẫn\n",
      "thực hiện Nghị định số 56/2011/NĐ-CP.Nội dung ông Hiếu hỏi chưa cung cấp đủ thông tin về khung\n",
      "năng lực vị trí việc làm được cấp có thẩm quyền phê duyệt và phân công công việc theo vị trí việc\n",
      "làm  để  làm  căn  cứ  xác  định  mức  phụ  cấp  ưu  đãi  nghề  cụ  thể  theo  quy  định  tại  Nghị  định  số\n",
      "56/2023/NĐ-CP ngày 4/7/2011 của Chính phủ.Viên chức hiện có mã ngạch 13.095 (chưa chuyển\n",
      "sang mã V.05) là chưa thực hiện đúng quy định và không thuộc đối tượng hưởng phụ cấp ưu đãi\n",
      "theo nghề đối với viên chức y tế dự phòng, y tế cơ sở theo quy định tại Nghị định số 05/2023/NĐCP\n",
      "ngày 15/2/2023 của Chính phủ.\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị nội dung của một số trang đầu tiên\n",
    "for i, document in enumerate(raw_documents[:5]):  # Lấy 5 trang đầu\n",
    "    print(f\"Trang {i + 1}:\")\n",
    "    print(document.page_content)\n",
    "    print(\"\\n\" + \"-\" * 40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Điều chỉnh kích thước đoạn văn cho phù hợp với nội dung dài\n",
    "    chunk_overlap=200  # Đảm bảo các đoạn ngắn không bị mất ngữ cảnh\n",
    ")\n",
    "docs = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Situation:\\nTôi xin hỏi, học sinh vừa tốt nghiệp THPT khi xét tuyển vào các trường cao đẳng thì có được tạm\\nmiễn thực hiện nghĩa vụ quân sự không?\\nAnswer:\\nBộ Quốc phòng trả lời vấn đề này như sau:Theo quy định tại Điểm g Khoản 1 Điều 41Luật Nghĩa vụ\\nquân sựnăm 2015, những công dân sau đây được tạm hoãn gọi nhập ngũ:\"g) Đang học tại cơ sở\\ngiáo dục phổ thông; đang được đào tạo trình độ đại học hệ chính quy thuộc cơ sở giáo dục đại học,\\ntrình độ cao đẳng hệ chính quy thuộc các cơ sở giáo dục nghề nghiệp trong một khóa đào tạo của\\nmột trình độ đào tạo\".Như vậy, công dân thuộc trường hợp nêu tại Điểm g Khoản 1 Điều 41 Luật\\nNghĩa vụ quân sự năm 2015 được tạm hoãn từ ngày công dân đã làm xong thủ tục nhập học và\\nđang học tập tại trường; chỉ được tạm hoãn gọi nhập ngũ trong một khóa đào tạo tập trung đầu\\ntiên, còn các khóa học tiếp theo thì không được tạm hoãn.', metadata={'source': 'data\\\\tinh_huong/output.pdf', 'page': 0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Download_Python\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Lấy embeddings từ token [CLS]\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m [phobert_embedding(doc\u001b[38;5;241m.\u001b[39mpage_content) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Lấy embeddings từ token [CLS]\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m [\u001b[43mphobert_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mphobert_embedding\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 11\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:825\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    833\u001b[0m     embedding_output,\n\u001b[0;32m    834\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    842\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    843\u001b[0m )\n\u001b[0;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:120\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    118\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 120\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m    122\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Tải model PhoBERT-large\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\")\n",
    "model = AutoModel.from_pretrained(\"vinai/phobert-large\")\n",
    "\n",
    "def phobert_embedding(texts):\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()  # Lấy embeddings từ token [CLS]\n",
    "\n",
    "embeddings = [phobert_embedding(doc.page_content) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (281) must match the existing size (258) at non-singleton dimension 1.  Target sizes: [8, 281].  Tensor sizes: [1, 258]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Tạo embeddings cho các văn bản\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mphobert_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings đã được tạo thành công.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 27\u001b[0m, in \u001b[0;36mphobert_embedding\u001b[1;34m(texts, batch_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 27\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Lấy embeddings từ token [CLS]\u001b[39;00m\n\u001b[0;32m     30\u001b[0m batch_embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download_Python\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:798\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    797\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 798\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (281) must match the existing size (258) at non-singleton dimension 1.  Target sizes: [8, 281].  Tensor sizes: [1, 258]"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Tải mô hình PhoBERT-large và tokenizer\n",
    "model_name = \"vinai/phobert-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()  # Đặt mô hình ở chế độ đánh giá\n",
    "\n",
    "# Hàm tạo embeddings với batch processing\n",
    "def phobert_embedding(texts, batch_size=8):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        # Chuyển các tensors sang GPU nếu có, nếu không thì giữ lại trên CPU\n",
    "        input_ids = input_ids.to(model.device)\n",
    "        attention_mask = attention_mask.to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Lấy embeddings từ token [CLS]\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "    return all_embeddings\n",
    "\n",
    "# Tải dữ liệu từ file PDF\n",
    "file_PDF = r'data\\tinh_huong/output.pdf'\n",
    "raw_documents = PyPDFLoader(file_PDF).load()\n",
    "\n",
    "# Chia dữ liệu thành các đoạn văn bản\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "docs = text_splitter.split_documents(raw_documents)\n",
    "texts = [doc.page_content for doc in docs]\n",
    "\n",
    "# Tạo embeddings cho các văn bản\n",
    "embeddings = phobert_embedding(texts, batch_size=8)\n",
    "\n",
    "print(\"Embeddings đã được tạo thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
